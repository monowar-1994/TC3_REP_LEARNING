{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary packages\n",
    "import os\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import json\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import regarding database handles\n",
    "import db_classes as orm\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graph_construction as gc\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File locations for specific files.\n",
    "graph_file_path = '/mnt/8tb/csenrc/representation_learning_codes/graph_file.json'\n",
    "index_file_path = '/mnt/8tb/csenrc/representation_learning_codes/index_file.json'\n",
    "# use the database connection URL if needed.\n",
    "connection_url = 'postgresql+psycopg2://csephase2:csephase@@localhost/darpa_tc3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects in the graph: 224146\n"
     ]
    }
   ],
   "source": [
    "# Let's load the graph first. \n",
    "\n",
    "provenance_graph = json.load(open(graph_file_path))\n",
    "print(\"Number of subjects in the graph: {}\".format(len(provenance_graph)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please note that the graph loading time is obnoxiously large. \n",
    "# Therefore, at this point, please refrain from doing anything that needs loading the graph from file multiple times.\n",
    "\n",
    "max_len = -1\n",
    "min_len = 1000000000000\n",
    "largest_subject_subgraph = -1\n",
    "smallest_subject_subgraph = -1\n",
    "count = 0\n",
    "small_graphs = []\n",
    "\n",
    "for subject in provenance_graph:\n",
    "    if len(provenance_graph[subject]['events']) > max_len:\n",
    "        max_len = len(provenance_graph[subject]['events'])\n",
    "        largest_subject_subgraph = subject\n",
    "    if len(provenance_graph[subject]['events']) < min_len:\n",
    "        min_len = len(provenance_graph[subject]['events'])\n",
    "        smallest_subject_subgraph = subject\n",
    "    if len(provenance_graph[subject]['events']) < 32:\n",
    "        count += 1\n",
    "        small_graphs.append(subject)  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently the largest subgraph is rooted at subject 74188 has the size of: 3049408\n",
      "Currently the smallest subgraph is rooted at subject 4 has the size of: 1\n",
      "Currently number of small subgraph is 124874\n"
     ]
    }
   ],
   "source": [
    "print(\"Currently the largest subgraph is rooted at subject {} has the size of: {}\".format(largest_subject_subgraph, max_len))\n",
    "print(\"Currently the smallest subgraph is rooted at subject {} has the size of: {}\".format(smallest_subject_subgraph, min_len))\n",
    "print(\"Currently number of small subgraph is {}\".format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wow that is a lot of events for a node. \n",
    "# Makes me wonder what a histogram for this data will look like. \n",
    "# In other words, what ate the node densities in the graoh. \n",
    "# Let's try it out. \n",
    "\n",
    "lengths = [] # Simple list will do, we are not tracking, we just want to see the distribution. \n",
    "\n",
    "for subject in provenance_graph:\n",
    "    lengths.append(len(provenance_graph[subject]['events']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now, let's plot the histogram. \n",
    "n_bins = 25\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "# We can set the number of bins with the *bins* keyword argument.\n",
    "#plt.scatter(np.arange(len(lengths)),np.log(lengths), marker='.')\n",
    "plt.hist(np.log(lengths), bins=n_bins)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Okay, that does not look great at all. \n",
    "A lot of nodes have more than 10^(3 to 6) number of events. Which means the timestamp difference varies wildly and plain normalization may not be an option anymore. Therefore, we resort to sinusoidal coding like the original BERT paper. \n",
    "# So, the question becomes how do we generate paths now. \n",
    "Well, here is another interesting situation. We can subsample the stream of events to generate the paths. But again, the question is now how do we encode the subject information in the path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max time delta: 270997933817167, max_sub_origin: 1522759935112293459, max_event_stamp = 1523030933046110626, max_sub = 10623\n",
      "Min time delta: -10001641, min_sub_origin: 1523218713175536589, min_event_stamp = 1523218713165534948, min_sub = 121235\n",
      "Negative count: 2819176, pct: 6.827477012164842\n"
     ]
    }
   ],
   "source": [
    "max_time_delta = 0\n",
    "max_sub_origin =  -1\n",
    "max_event_stamp = -1\n",
    "max_sub = -1\n",
    "\n",
    "min_time_delta = 100000000000000\n",
    "min_sub_origin =  -1\n",
    "min_event_stamp = -1\n",
    "min_sub = -1\n",
    "negative_count = 0\n",
    "total_count = 0\n",
    "\n",
    "for subject in provenance_graph:\n",
    "    subject_timestamp = provenance_graph[subject]['sub'][2]\n",
    "    event_list = provenance_graph[subject]['events']\n",
    "    total_count += len(event_list)\n",
    "    if subject_timestamp != 0:\n",
    "        for event in event_list:\n",
    "            if event[0][3] != 0:\n",
    "                time_delta = event[0][3] - subject_timestamp\n",
    "\n",
    "                if time_delta<=0:\n",
    "                    negative_count +=1 \n",
    "            \n",
    "                if time_delta > max_time_delta:    \n",
    "                    max_time_delta = time_delta\n",
    "                    max_sub_origin = subject_timestamp\n",
    "                    max_event_stamp = event[0][3]\n",
    "                    max_sub = subject\n",
    "\n",
    "                if time_delta < min_time_delta:\n",
    "                    min_time_delta = time_delta\n",
    "                    min_sub_origin = subject_timestamp\n",
    "                    min_event_stamp = event[0][3]\n",
    "                    min_sub = subject\n",
    "        \n",
    "print(\"Max time delta: {}, max_sub_origin: {}, max_event_stamp = {}, max_sub = {}\".format(max_time_delta, max_sub_origin, max_event_stamp, max_sub))\n",
    "print(\"Min time delta: {}, min_sub_origin: {}, min_event_stamp = {}, min_sub = {}\".format(min_time_delta, min_sub_origin, min_event_stamp, min_sub))\n",
    "print(\"Negative count: {}, pct: {}\".format(negative_count, (negative_count/total_count)*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looks like 6.82% events are have negative time delta which is not possible for us to use. In this case, the ususal approach is to drop the data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events kept: 38472446, number of events removed: 2819176, percentage: 6.827477012164841\n"
     ]
    }
   ],
   "source": [
    "cleaned_provenance_graph = dict() # Pruned graph object\n",
    "remove_count = 0 # Number of events that have been removed from the graph\n",
    "keep_count = 0 # Number of events that have been retained from the graph\n",
    "\n",
    "for subject in provenance_graph:\n",
    "\n",
    "    cleaned_provenance_graph[subject] = dict()\n",
    "    cleaned_provenance_graph[subject]['sub'] = provenance_graph[subject]['sub'] # Saving the subject identity.\n",
    "    \n",
    "    subject_timestamp = provenance_graph[subject]['sub'][2]\n",
    "    event_list = provenance_graph[subject]['events'] \n",
    "    temp_event_list = []\n",
    "    for event in event_list:\n",
    "        if event[0][3] != 0:\n",
    "            time_delta = event[0][3] - subject_timestamp\n",
    "            if time_delta>0:\n",
    "                temp_event_list.append(event)\n",
    "            else:\n",
    "                remove_count +=1\n",
    "        else:\n",
    "            remove_count+=1 \n",
    "\n",
    "    cleaned_provenance_graph[subject]['events'] = temp_event_list\n",
    "    keep_count += len(temp_event_list)\n",
    "    \n",
    "print(\"Number of events kept: {}, number of events removed: {}, percentage: {}\".format(keep_count, remove_count, ((100*remove_count)/(remove_count+keep_count) )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max time delta: 270997933817167, max_sub_origin: 1522759935112293459, max_event_stamp = 1523030933046110626, max_sub = 10623\n",
      "Min time delta: 1472570, min_sub_origin: 1523556159254718787, min_event_stamp = 1523556159256191357, min_sub = 200097\n",
      "Negative count: 0, pct: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Running the same code block on the pruned provenance graph\n",
    "max_time_delta = 0\n",
    "max_sub_origin =  -1\n",
    "max_event_stamp = -1\n",
    "max_sub = -1\n",
    "\n",
    "min_time_delta = 100000000000000\n",
    "min_sub_origin =  -1\n",
    "min_event_stamp = -1\n",
    "min_sub = -1\n",
    "negative_count = 0\n",
    "total_count = 0\n",
    "\n",
    "for subject in cleaned_provenance_graph:\n",
    "    subject_timestamp = cleaned_provenance_graph[subject]['sub'][2]\n",
    "    event_list = cleaned_provenance_graph[subject]['events']\n",
    "    total_count += len(event_list)\n",
    "    if subject_timestamp != 0:\n",
    "        for event in event_list:\n",
    "            if event[0][3] != 0:\n",
    "                time_delta = event[0][3] - subject_timestamp\n",
    "\n",
    "                if time_delta<=0:\n",
    "                    negative_count +=1 \n",
    "            \n",
    "                if time_delta > max_time_delta:    \n",
    "                    max_time_delta = time_delta\n",
    "                    max_sub_origin = subject_timestamp\n",
    "                    max_event_stamp = event[0][3]\n",
    "                    max_sub = subject\n",
    "\n",
    "                if time_delta < min_time_delta:\n",
    "                    min_time_delta = time_delta\n",
    "                    min_sub_origin = subject_timestamp\n",
    "                    min_event_stamp = event[0][3]\n",
    "                    min_sub = subject\n",
    "        \n",
    "print(\"Max time delta: {}, max_sub_origin: {}, max_event_stamp = {}, max_sub = {}\".format(max_time_delta, max_sub_origin, max_event_stamp, max_sub))\n",
    "print(\"Min time delta: {}, min_sub_origin: {}, min_event_stamp = {}, min_sub = {}\".format(min_time_delta, min_sub_origin, min_event_stamp, min_sub))\n",
    "print(\"Negative count: {}, pct: {}\".format(negative_count, (negative_count/total_count)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.796340601824141e-15\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "MAX_TIME_DELTA = 270997933817167\n",
    "NUMERATOR = np.pi * 0.5 * (1/MAX_TIME_DELTA)\n",
    "print(NUMERATOR)\n",
    "print(np.sin(NUMERATOR*MAX_TIME_DELTA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_sequence(subject_id, encoding = None, sequence_size = 31 ):\n",
    "    \n",
    "    subject_start_time_stamp = cleaned_provenance_graph[subject_id]['sub'][2]\n",
    "    events = cleaned_provenance_graph[subject_id]['events']\n",
    "    sampled_events = None\n",
    "    \n",
    "    if len(events)>sequence_size:\n",
    "        sampled_events = random.sample(events, k=sequence_size)\n",
    "    else:\n",
    "        sampled_events = events\n",
    "\n",
    "    sampled_events = sorted(sampled_events, key=lambda x:x[0][3])\n",
    "\n",
    "    result_array = np.zeros((sequence_size*8)+2)\n",
    "    index = 2\n",
    "    \n",
    "    for event in sampled_events:\n",
    "        temp = np.zeros(8)\n",
    "\n",
    "        temp[0] = event[0][0] # Normalized event type\n",
    "        temp[1] = event[0][1] # Normalized predicate object 1 type\n",
    "        temp[2] = event[0][2] # Normalized predicate object 2 type\n",
    "        temp[3] = event[0][4] # Normalized event name\n",
    "\n",
    "        if event[1] is not None:\n",
    "            temp[4] = event[1][0] # Details of predicate object 1 if available\n",
    "            temp[5] = event[1][1] \n",
    "        if event[2] is not None:\n",
    "            temp[6] = event[2][0] # Details of predicate object 2 if available\n",
    "            temp[7] = event[2][1]\n",
    "        \n",
    "        \n",
    "        time_delta = event[0][3] - subject_start_time_stamp \n",
    "\n",
    "        if encoding == 'sine':\n",
    "            result_array[index:index+8] = temp * np.sin(NUMERATOR * time_delta)\n",
    "        elif encoding == 'cosine':\n",
    "            result_array[index:index+8] = temp * np.cos(NUMERATOR * time_delta)\n",
    "        elif encoding =='linear':\n",
    "            result_array[index:index+8] = temp * (time_delta/MAX_TIME_DELTA)\n",
    "        elif encoding is None:\n",
    "            result_array[index:index+8] = temp\n",
    "        \n",
    "        index+=8\n",
    "\n",
    "    result_array[0] = cleaned_provenance_graph[subject_id]['sub'][0]\n",
    "    result_array[1] = cleaned_provenance_graph[subject_id]['sub'][1]\n",
    "\n",
    "    return result_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25      , 0.        , 0.04040804, 0.07653039, 0.07653039,\n",
       "       0.02577866, 0.18367292, 0.        , 0.18367292, 0.        ,\n",
       "       0.06347334, 0.14692903, 0.        , 0.18559456, 0.35262967,\n",
       "       0.        , 0.        , 0.        , 0.11716224, 0.22189819,\n",
       "       0.22189819, 0.07474465, 0.53255564, 0.        , 0.53255564,\n",
       "       0.        , 0.13537321, 0.31336391, 0.        , 0.39582809,\n",
       "       0.75207338, 0.        , 0.        , 0.        , 0.17285642,\n",
       "       0.32737959, 0.32737959, 0.11027523, 0.78571101, 0.        ,\n",
       "       0.78571101, 0.        , 0.27946781, 0.        , 0.        ,\n",
       "       0.56239653, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.29753899, 0.        , 0.        , 0.59876267, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.16029968, 0.37106408,\n",
       "       0.        , 0.46871252, 0.89055378, 0.        , 0.        ,\n",
       "       0.        , 0.21619595, 0.40946203, 0.40946203, 0.13792405,\n",
       "       0.98270887, 0.        , 0.98270887, 0.        , 0.3397414 ,\n",
       "       0.        , 0.        , 0.68369011, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.17985523, 0.41633156, 0.        ,\n",
       "       0.52589249, 0.99919573, 0.        , 0.        , 0.        ,\n",
       "       0.3362568 , 0.        , 0.        , 0.67667777, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.33159447, 0.        ,\n",
       "       0.        , 0.66729536, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.21137523, 0.40033187, 0.40033187, 0.13484863,\n",
       "       0.96079648, 0.        , 0.96079648, 0.        , 0.17291267,\n",
       "       0.40026081, 0.        , 0.50559261, 0.96062595, 0.        ,\n",
       "       0.        , 0.        , 0.32379238, 0.        , 0.        ,\n",
       "       0.65159458, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.17021946, 0.39402653, 0.        , 0.49771772, 0.94566367,\n",
       "       0.        , 0.        , 0.        , 0.31565954, 0.        ,\n",
       "       0.        , 0.63522818, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.31563318, 0.        , 0.        , 0.63517513,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.31323307,\n",
       "       0.        , 0.        , 0.63034519, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.16361297, 0.37873372, 0.        ,\n",
       "       0.47840048, 0.90896092, 0.        , 0.        , 0.        ,\n",
       "       0.1591352 , 0.36836851, 0.        , 0.46530759, 0.88408443,\n",
       "       0.        , 0.        , 0.        , 0.19243476, 0.36445978,\n",
       "       0.36445978, 0.1227654 , 0.87470347, 0.        , 0.87470347,\n",
       "       0.        , 0.14658797, 0.33932401, 0.        , 0.4286198 ,\n",
       "       0.81437762, 0.        , 0.        , 0.        , 0.17290337,\n",
       "       0.3274685 , 0.3274685 , 0.11030518, 0.78592439, 0.        ,\n",
       "       0.78592439, 0.        , 0.13517809, 0.31291224, 0.        ,\n",
       "       0.39525757, 0.75098937, 0.        , 0.        , 0.        ,\n",
       "       0.25060173, 0.        , 0.        , 0.5043069 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21873897, 0.        ,\n",
       "       0.        , 0.44018677, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.12807063, 0.24255802, 0.24255802, 0.08170375,\n",
       "       0.58213924, 0.        , 0.58213924, 0.        , 0.0964805 ,\n",
       "       0.18272822, 0.18272822, 0.06155056, 0.43854774, 0.        ,\n",
       "       0.43854774, 0.        , 0.14572142, 0.        , 0.        ,\n",
       "       0.29324744, 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_sequence('74188', encoding='sine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224146\n"
     ]
    }
   ],
   "source": [
    "subject_list = list(cleaned_provenance_graph.keys())\n",
    "print(len(subject_list))\n",
    "random.shuffle(subject_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator( datasource , encoding_scheme = None, batch_size = 32, sequence_size = 31):\n",
    "    while True:\n",
    "        x = np.zeros((batch_size, (sequence_size*8)+2))\n",
    "        y = np.zeros((batch_size, (sequence_size*8)+2))\n",
    "\n",
    "        subjects = random.sample(datasource, k=batch_size)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            x[i] = get_random_sequence(subjects[i], encoding=encoding_scheme ,sequence_size= sequence_size)\n",
    "            y[i] = x[i]\n",
    "\n",
    "        yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_autoencoder(input_length):\n",
    "    input_layer = tf.keras.Input(shape=(input_length, ))\n",
    "    layer_0_down = tf.keras.layers.Dense(512, activation ='relu')(input_layer)\n",
    "    layer_1_down = tf.keras.layers.Dense(256, activation ='relu')(layer_0_down)\n",
    "    layer_2_down =  tf.keras.layers.Dense(128, activation ='relu')(layer_1_down)\n",
    "    # layer_3_down = tf.keras.layers.Dense(64, activation ='relu')(layer_2_down)\n",
    "    bottleneck_layer = tf.keras.layers.Dense(32, activation ='relu')(layer_2_down)\n",
    "    # layer_1_up = tf.keras.layers.Dense(64, activation ='relu')(bottleneck_layer)\n",
    "    layer_2_up = tf.keras.layers.Dense(128, activation ='relu')(bottleneck_layer) \n",
    "    layer_3_up = tf.keras.layers.Dense(256, activation ='relu')(layer_2_up)\n",
    "    layer_4_up = tf.keras.layers.Dense(512, activation ='relu')(layer_3_up)\n",
    "    output_layer = tf.keras.layers.Dense(input_length, activation ='relu')(layer_4_up)\n",
    "\n",
    "    autoencoder_model = tf.keras.Model(input_layer, output_layer)\n",
    "\n",
    "    return autoencoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 250)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               128512    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 250)               128250    \n",
      "=================================================================\n",
      "Total params: 593,946\n",
      "Trainable params: 593,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_length = 31\n",
    "autoencoder = get_autoencoder(seq_length*8 + 2)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dataset_length = 224146\n",
    "\n",
    "training_length = 200000\n",
    "validation_length = 24146\n",
    "\n",
    "training_data = subject_list[:training_length]\n",
    "validation_data = subject_list[training_length:]\n",
    "\n",
    "train_seq_generator = generator(training_data, encoding_scheme=None, batch_size=32, sequence_size=31)\n",
    "valid_seq_generator = generator(validation_data, encoding_scheme=None, batch_size=32, sequence_size=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(loss=tf.keras.losses.MSE, optimizer=tf.keras.optimizers.Adam(learning_rate=1e-04), metrics=[tf.keras.metrics.Accuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 1049.1577 - accuracy: 0.5714 - val_loss: 0.9305 - val_accuracy: 0.6759\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.0444 - accuracy: 0.6642 - val_loss: 0.0011 - val_accuracy: 0.6671\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 5.6975e-04 - accuracy: 0.6518 - val_loss: 5.2702e-04 - val_accuracy: 0.6458\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 5.3628e-04 - accuracy: 0.6521 - val_loss: 7.5331e-04 - val_accuracy: 0.6318\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 4.3264e-04 - accuracy: 0.6584 - val_loss: 2.2471e-04 - val_accuracy: 0.6696\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 4.1902e-04 - accuracy: 0.6526 - val_loss: 4.1603e-04 - val_accuracy: 0.6514\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.0525 - accuracy: 0.6596 - val_loss: 4.6171e-04 - val_accuracy: 0.6762\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.1020 - accuracy: 0.6649 - val_loss: 3.2871e-04 - val_accuracy: 0.6695\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 5.2083e-04 - accuracy: 0.6689 - val_loss: 2.2445e-04 - val_accuracy: 0.6413\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.0799 - accuracy: 0.6652 - val_loss: 0.0428 - val_accuracy: 0.6829\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.0029 - accuracy: 0.6657 - val_loss: 1.9705e-04 - val_accuracy: 0.6583\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 2.4105e-04 - accuracy: 0.6678 - val_loss: 4.3010e-04 - val_accuracy: 0.6788\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.0906 - accuracy: 0.6721 - val_loss: 0.0013 - val_accuracy: 0.6679\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 6.2514e-04 - accuracy: 0.6721 - val_loss: 3.0908e-04 - val_accuracy: 0.6584\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 4.0566e-04 - accuracy: 0.6633 - val_loss: 7.4267e-04 - val_accuracy: 0.6563\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 3.2159e-04 - accuracy: 0.6699 - val_loss: 2.0104e-04 - val_accuracy: 0.6803\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 2.8523e-04 - accuracy: 0.6687 - val_loss: 1.9852e-04 - val_accuracy: 0.6558\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 0.0500 - accuracy: 0.6645 - val_loss: 0.5147 - val_accuracy: 0.6766\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 0.0457 - accuracy: 0.6655 - val_loss: 5.9730e-04 - val_accuracy: 0.6733\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 4.8619e-04 - accuracy: 0.6669 - val_loss: 3.6806e-04 - val_accuracy: 0.6568\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 0.1014 - accuracy: 0.6650 - val_loss: 0.1037 - val_accuracy: 0.6795\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.0198 - accuracy: 0.6643 - val_loss: 2.0193e-04 - val_accuracy: 0.6858\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 5.1474e-04 - accuracy: 0.6647 - val_loss: 1.9989e-04 - val_accuracy: 0.6640\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 3.1177e-04 - accuracy: 0.6712 - val_loss: 2.0392e-04 - val_accuracy: 0.6740\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 3.6113e-04 - accuracy: 0.6689 - val_loss: 1.9703e-04 - val_accuracy: 0.6876\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 3.8324e-04 - accuracy: 0.6666 - val_loss: 2.1083e-04 - val_accuracy: 0.6833\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 3.4556e-04 - accuracy: 0.6692 - val_loss: 8.4094e-04 - val_accuracy: 0.6555\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 5.6577e-04 - accuracy: 0.6697 - val_loss: 2.6760e-04 - val_accuracy: 0.6645\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 3.3368e-04 - accuracy: 0.6671 - val_loss: 2.1307e-04 - val_accuracy: 0.6672\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 4.5324e-04 - accuracy: 0.6764 - val_loss: 2.8675e-04 - val_accuracy: 0.6578\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 4.6831e-04 - accuracy: 0.6772 - val_loss: 1.9888e-04 - val_accuracy: 0.6492\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 1.9970 - accuracy: 0.6687 - val_loss: 15.6445 - val_accuracy: 0.6879\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 1.9644 - accuracy: 0.6687 - val_loss: 6.3029e-04 - val_accuracy: 0.6799\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 5.4647e-04 - accuracy: 0.6647 - val_loss: 6.2715e-04 - val_accuracy: 0.6661\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.2826 - accuracy: 0.6723 - val_loss: 0.1126 - val_accuracy: 0.6703\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 0.0091 - accuracy: 0.6632 - val_loss: 5.0159e-04 - val_accuracy: 0.6762\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 4.0408e-04 - accuracy: 0.6640 - val_loss: 7.7084e-04 - val_accuracy: 0.6677\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 5.3020e-04 - accuracy: 0.6643 - val_loss: 1.9928e-04 - val_accuracy: 0.6878\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 4.7422e-04 - accuracy: 0.6665 - val_loss: 9.8165e-04 - val_accuracy: 0.6622\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 2.3012e-04 - accuracy: 0.6681 - val_loss: 1.9532e-04 - val_accuracy: 0.6675\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 5.8550e-04 - accuracy: 0.6649 - val_loss: 2.0723e-04 - val_accuracy: 0.6763\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 4.4545e-04 - accuracy: 0.6668 - val_loss: 3.6139e-04 - val_accuracy: 0.6957\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.3558 - accuracy: 0.6669 - val_loss: 0.3726 - val_accuracy: 0.6675\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.0188 - accuracy: 0.6734 - val_loss: 2.4360e-04 - val_accuracy: 0.6699\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 3.6375e-04 - accuracy: 0.6638 - val_loss: 1.9142e-04 - val_accuracy: 0.6676\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 3.5829e-04 - accuracy: 0.6737 - val_loss: 2.3408e-04 - val_accuracy: 0.6699\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.2802 - accuracy: 0.6728 - val_loss: 6.1710e-04 - val_accuracy: 0.6524\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 2.4346e-04 - accuracy: 0.6708 - val_loss: 0.0011 - val_accuracy: 0.6599\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 2.8756e-04 - accuracy: 0.6771 - val_loss: 2.2660e-04 - val_accuracy: 0.6805\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 3.3742e-04 - accuracy: 0.6759 - val_loss: 6.0799e-04 - val_accuracy: 0.6643\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 2.5489e-04 - accuracy: 0.6665 - val_loss: 1.9157e-04 - val_accuracy: 0.6857\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 4.0418e-04 - accuracy: 0.6734 - val_loss: 0.0010 - val_accuracy: 0.6668\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 3.3807e-04 - accuracy: 0.6715 - val_loss: 1.9063e-04 - val_accuracy: 0.6664\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.2692 - accuracy: 0.6685 - val_loss: 0.0013 - val_accuracy: 0.6694\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 3.9569e-04 - accuracy: 0.6715 - val_loss: 7.0287e-04 - val_accuracy: 0.6911\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 4.2202e-04 - accuracy: 0.6646 - val_loss: 4.0343e-04 - val_accuracy: 0.6692\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.2168 - accuracy: 0.6702 - val_loss: 0.0047 - val_accuracy: 0.6732\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 6.0914e-04 - accuracy: 0.6692 - val_loss: 1.9575e-04 - val_accuracy: 0.6380\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 3.5469e-04 - accuracy: 0.6710 - val_loss: 8.4057e-04 - val_accuracy: 0.6781\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 3.3794e-04 - accuracy: 0.6702 - val_loss: 2.0707e-04 - val_accuracy: 0.6740\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 2.9619e-04 - accuracy: 0.6719 - val_loss: 1.9854e-04 - val_accuracy: 0.6749\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 3.4936e-04 - accuracy: 0.6710 - val_loss: 1.9236e-04 - val_accuracy: 0.6619\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 0.2374 - accuracy: 0.6583 - val_loss: 0.0808 - val_accuracy: 0.6823\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.0054 - accuracy: 0.6775 - val_loss: 2.9881e-04 - val_accuracy: 0.6870\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 3.0356e-04 - accuracy: 0.6676 - val_loss: 7.6121e-04 - val_accuracy: 0.6734\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 3.4348e-04 - accuracy: 0.6692 - val_loss: 2.8266e-04 - val_accuracy: 0.6600\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 4.0614e-04 - accuracy: 0.6667 - val_loss: 4.1930e-04 - val_accuracy: 0.6881\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 4.5701e-04 - accuracy: 0.6619 - val_loss: 2.2487e-04 - val_accuracy: 0.6669\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 3.5099e-04 - accuracy: 0.6612 - val_loss: 6.0775e-04 - val_accuracy: 0.6838\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 3.7148e-04 - accuracy: 0.6656 - val_loss: 6.4739e-04 - val_accuracy: 0.6874\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 3.8392e-04 - accuracy: 0.6715 - val_loss: 5.2709e-04 - val_accuracy: 0.6696\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.2375 - accuracy: 0.6785 - val_loss: 0.0075 - val_accuracy: 0.6802\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 8.2438e-04 - accuracy: 0.6696 - val_loss: 3.9705e-04 - val_accuracy: 0.6857\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 3.8148e-04 - accuracy: 0.6670 - val_loss: 4.1456e-04 - val_accuracy: 0.6859\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 4.6762e-04 - accuracy: 0.6711 - val_loss: 5.3482e-04 - val_accuracy: 0.6750\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 3.6432e-04 - accuracy: 0.6714 - val_loss: 2.0317e-04 - val_accuracy: 0.6949\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 3.7006e-04 - accuracy: 0.6713 - val_loss: 2.2217e-04 - val_accuracy: 0.6994\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 0.1055 - accuracy: 0.6674 - val_loss: 0.0070 - val_accuracy: 0.6696\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.0013 - accuracy: 0.6705 - val_loss: 0.0012 - val_accuracy: 0.6563\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.0251 - accuracy: 0.6673 - val_loss: 6.5843e-04 - val_accuracy: 0.6571\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 1.0981 - accuracy: 0.6681 - val_loss: 0.0012 - val_accuracy: 0.6725\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 4.0090e-04 - accuracy: 0.6637 - val_loss: 4.5203e-04 - val_accuracy: 0.6786\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 3.2864e-04 - accuracy: 0.6704 - val_loss: 2.0770e-04 - val_accuracy: 0.6477\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 4.5317e-04 - accuracy: 0.6687 - val_loss: 5.1942e-04 - val_accuracy: 0.6530\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 4.3566e-04 - accuracy: 0.6653 - val_loss: 5.6498e-04 - val_accuracy: 0.6939\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 2.7240e-04 - accuracy: 0.6724 - val_loss: 2.9460e-04 - val_accuracy: 0.6698\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 2.9404e-04 - accuracy: 0.6723 - val_loss: 2.7872e-04 - val_accuracy: 0.6755\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 2.7257e-04 - accuracy: 0.6673 - val_loss: 3.3523e-04 - val_accuracy: 0.6676\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 3.7416e-04 - accuracy: 0.6628 - val_loss: 3.3211e-04 - val_accuracy: 0.6560\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 3.0487e-04 - accuracy: 0.6713 - val_loss: 2.2246e-04 - val_accuracy: 0.6729\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 2.9186e-04 - accuracy: 0.6673 - val_loss: 2.0627e-04 - val_accuracy: 0.6693\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 3.1987e-04 - accuracy: 0.6657 - val_loss: 1.9533e-04 - val_accuracy: 0.6827\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 3.9612e-04 - accuracy: 0.6692 - val_loss: 0.0011 - val_accuracy: 0.6643\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 4.6121e-04 - accuracy: 0.6638 - val_loss: 1.9954e-04 - val_accuracy: 0.6613\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 3.7069e-04 - accuracy: 0.6706 - val_loss: 7.2764e-04 - val_accuracy: 0.6745\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.0015 - accuracy: 0.6642 - val_loss: 7.5782e-04 - val_accuracy: 0.6653\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 3.1926e-04 - accuracy: 0.6640 - val_loss: 6.7680e-04 - val_accuracy: 0.6735\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 7.8064e-04 - accuracy: 0.6690 - val_loss: 0.0017 - val_accuracy: 0.6585\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 5.0378e-04 - accuracy: 0.6684 - val_loss: 7.9393e-04 - val_accuracy: 0.6673\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 3.7187e-04 - accuracy: 0.6696 - val_loss: 6.7505e-04 - val_accuracy: 0.6788\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit_generator(train_seq_generator, steps_per_epoch=100, epochs=100, validation_data = valid_seq_generator, validation_steps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Okay , that didn't work out well. We can make it a convNet based autoencoder and see what is up. If it doesn't work, then we got a problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_autoencoder():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a01f599b34edce01dd96621430605e3428cfca8a7f3f7e0aec5d26beeaa95b07"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('envphase2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
